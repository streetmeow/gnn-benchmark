# multi_run.py (Grid Search ì™„ì„±ë³¸)
import hydra
from hydra import initialize, compose
from omegaconf import OmegaConf
import datetime
import torch
import gc
import traceback
import itertools
import os

# [í•µì‹¬] main.pyì—ì„œ ì•Œë§¹ì´ í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
from main import run_experiment


HP_SEARCH_SPACE = {

    # ======================

    # 1) CITESEER

    # ======================

    ("citeseer", "gcn"): {

        "layer": [2],                 # 2-layer ë” ì•ˆì •ì 

        "hidden": [64, 128],

        "lr": [0.01, 0.005],

        "dropout": [0.5],

        "wd": [5e-5, 5e-4],

    },

    ("citeseer", "gat"): {

        "layer": [2, 3],

        "hidden": [128],

        "lr": [0.001, 0.005, 0.01],

        "dropout": [0.2, 0.5],

        "wd": [5e-4],

    },

    ("citeseer", "gin"): {

        "layer": [2],

        "hidden": [64, 128],

        "lr": [0.001, 0.0005],

        "dropout": [0.2, 0.5],

        "wd": [5e-5, 5e-4],

    },

    ("citeseer", "graphsage"): {

        "layer": [2, 3],

        "hidden": [128],

        "lr": [0.001, 0.005, 0.01],

        "dropout": [0.5],

        "wd": [5e-5, 5e-4],

    },



    # ======================

    # 2) CORA

    # ======================

    ("cora", "gcn"): {

        "layer": [2, 3],

        "hidden": [128],

        "lr": [0.01, 0.005],

        "dropout": [0.2, 0.5],

        "wd": [5e-5, 5e-4],

    },

    ("cora", "gat"): {

        "layer": [3],

        "hidden": [128],

        "lr": [0.01, 0.001, 0.005],

        "dropout": [0.2, 0.5],

        "wd": [5e-5, 5e-4],

    },

    ("cora", "gin"): {

        "layer": [2],

        "hidden": [128],

        "lr": [0.001, 0.0005, 0.005],

        "dropout": [0.2, 0.5],

        "wd": [5e-5, 5e-4],

    },

    ("cora", "graphsage"): {

        "layer": [3],

        "hidden": [64, 128],

        "lr": [0.001, 0.01, 0.005],

        "dropout": [0.5],

        "wd": [5e-5, 5e-4],

    },



    # ======================

    # 3) PUBMED

    # ======================

    ("pubmed", "gcn"): {

        "layer": [2, 3],

        "hidden": [64, 128],

        "lr": [0.01, 0.005],

        "dropout": [0.2, 0.5],

        "wd": [5e-4],

    },

    ("pubmed", "gat"): {

        "layer": [2, 3],

        "hidden": [64, 128],

        "lr": [0.01, 0.005],

        "dropout": [0.2, 0.5],

        "wd": [5e-4],

    },

    ("pubmed", "gin"): {

        "layer": [2, 3],

        "hidden": [64, 128],

        "lr": [0.005, 0.01],

        "dropout": [0.2, 0.5],

        "wd": [5e-4],

    },

    ("pubmed", "graphsage"): {

        "layer": [2, 3],

        "hidden": [64, 128],

        "lr": [0.001],

        "dropout": [0.2, 0.5],

        "wd": [5e-5],

    },



    # ======================

    # 4) ACTOR

    # ======================

    ("actor", "gcn"): {

        "layer": [2, 3],

        "hidden": [128],

        "lr": [0.001, 0.005],

        "dropout": [0.5, 0.2],  # dropout ì˜í–¥ ëª…í™•íˆ ê¸ì •ì 

        "wd": [5e-5, 5e-4],

    },

    ("actor", "gat"): {

        "layer": [2],

        "hidden": [64, 128],

        "lr": [0.005, 0.01],

        "dropout": [0.5, 0.2],

        "wd": [5e-4],

    },

    ("actor", "gin"): {

        "layer": [2],

        "hidden": [64, 128],

        "lr": [0.01, 0.005],

        "dropout": [0.2, 0.5],

        "wd": [5e-5, 5e-4],

    },

    ("actor", "graphsage"): {

        "layer": [3],   # actorì—ì„œ GraphSAGEëŠ” 3 layer ìš°ì„¸

        "hidden": [64, 128],

        "lr": [0.001, 0.005, 0.01],

        "dropout": [0.2, 0.5],

        "wd": [5e-5, 5e-4],

    },



    # ======================

    # 5) OGBN-PRODUCTS

    # ======================

    ("ogbn-products", "gcn"): {

        "layer": [3],

        "hidden": [128],

        "lr": [0.001, 0.01, 0.005],

        "dropout": [0.2, 0.5],

        "wd": [5e-5],

    },

    ("ogbn-products", "gat"): {

        "layer": [3],

        "hidden": [128, 64],

        "lr": [0.001, 0.005],

        "dropout": [0.2, 0.5],

        "wd": [5e-5],

    },

    ("ogbn-products", "gin"): {

        "layer": [2, 3],

        "hidden": [128],

        "lr": [0.001],

        "dropout": [0.2, 0.5],

        "wd": [5e-5, 5e-4],

    },

    ("ogbn-products", "graphsage"): {

        "layer": [3],

        "hidden": [128],

        "lr": [0.001, 0.005, 0.01],

        "dropout": [0.2, 0.5],

        "wd": [5e-5],

    },



    # ======================

    # 6) OGBN-ARXIV

    # ======================

    ("ogbn-arxiv", "gcn"): {

        "layer": [2, 3],

        "hidden": [128],

        "lr": [0.001, 0.01, 0.005],

        "dropout": [0.2, 0.5],

        "wd": [5e-5],

    },

    ("ogbn-arxiv", "gat"): {

        "layer": [3],

        "hidden": [64, 128],

        "lr": [0.001, 0.01, 0.005],

        "dropout": [0.2, 0.5],

        "wd": [5e-5],

    },

    ("ogbn-arxiv", "gin"): {

        "layer": [2, 3],

        "hidden": [128],

        "lr": [0.001],

        "dropout": [0.2, 0.5],

        "wd": [5e-5, 5e-4],

    },

    ("ogbn-arxiv", "graphsage"): {

        "layer": [3],

        "hidden": [128],

        "lr": [0.001, 0.01, 0.005],

        "dropout": [0.2, 0.5],

        "wd": [5e-5, 5e-4],

    },

}


def run_grid_search():
    # KST ë¦¬ì¡¸ë²„ ë“±ë¡
    if not OmegaConf.has_resolver("kst"):
        OmegaConf.register_new_resolver("kst", lambda fmt: datetime.datetime.now(
            datetime.timezone(datetime.timedelta(hours=9))).strftime(fmt))

    # 1. íƒìƒ‰ ê³µê°„ ì •ì˜
    search_space = {
        # "dataset": ["cora", "citeseer", "pubmed", "ogbn-arxiv", "ogbn-products", "actor"],
        "dataset": ["ogbn-arxiv"],
        "model": ["gcn", "graphsage", "gat", "gin"],
        "seed": [5],
        # í•˜ì´í¼íŒŒë¼ë¯¸í„°
        "model.hidden_dim": [64, 128],  # ì˜ˆì‹œë¡œ ì¤„ì„
        "model.dropout": [0.2, 0.5],
        "train.lr": [0.001, 0.01],
        "train.weight_decay": [5e-4, 5e-5]
    }

    # 2. Cartesian Product ìƒì„±
    keys, values = zip(*search_space.items())
    combinations = list(itertools.product(*values))

    print(f"ğŸš€ Total Configurations to run: {len(combinations)}")

    with initialize(version_base=None, config_path="configs"):

        for i, combination in enumerate(combinations):
            # í˜„ì¬ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
            param_dict = dict(zip(keys, combination))

            # ì§„í–‰ìƒí™© ì¶œë ¥
            print(f"\n==========================================================")
            print(f"ğŸ§© [Grid Search layer 2 {i + 1}/{len(combinations)}] Params: {param_dict}")

            d_name = param_dict["dataset"]
            m_name = param_dict["model"]

            # 3. Overrides ë¦¬ìŠ¤íŠ¸ ìƒì„± (ê¸°ë³¸ íŒŒë¼ë¯¸í„°)
            overrides = []
            for k, v in param_dict.items():
                overrides.append(f"{k}={v}")
            overrides.append("gpu_id=0")

            # [WandB Grouping] í•œ ëˆˆì— ë³´ê¸° ì¢‹ê²Œ ê·¸ë£¹ ì´ë¦„ ì„¤ì •
            # overrides.append(f"logging.experiment_strategy_name=GridSearch_v1")

            # 4. ì¡°ê±´ë¶€ ë¡œì§ (Logic) - ì•ˆì „ì¥ì¹˜ í¬í•¨
            is_large_dataset = d_name in ["ogbn-products", "ogbn-arxiv"]

            # (1) ìƒ˜í”ŒëŸ¬ í™œì„±í™” ì—¬ë¶€ ë° ë°°ì¹˜ ì‚¬ì´ì¦ˆ ê²°ì •
            if is_large_dataset or m_name == "graphsage":
                overrides.append("dataset.use_sampler=true")
                overrides.append("sampler.batch_size=512")

                # ë°ì´í„°ì…‹ë³„ ë°°ì¹˜ ì‚¬ì´ì¦ˆ
                if is_large_dataset:
                    overrides.append("sampler.batch_size=1024")
            else:
                overrides.append("dataset.use_sampler=false")

            if d_name == "ogbn-products":
                overrides.append("train.epochs=100")
            elif d_name == "ogbn-arxiv":
                overrides.append("train.epochs=80")
            elif d_name == "pubmed":
                overrides.append("train.epochs=140")
            elif d_name == "actor":
                overrides.append("train.epochs=250")
            elif d_name == "citeseer":
                overrides.append("train.epochs=180")
            elif d_name == "cora":
                overrides.append("train.epochs=150")

            # (2) ëª¨ë¸ë³„ ë ˆì´ì–´ ë° ìƒ˜í”ŒëŸ¬ ì‚¬ì´ì¦ˆ ë§¤ì¹­ (ì¤‘ìš”!)
            overrides.append("model.num_layers=2")
            overrides.append("model.sizes=[15,10]")

            try:
                if i == 0:
                    gc.collect()  # 1. íŒŒì´ì¬ ì“°ë ˆê¸° ìˆ˜ê±° (ì°¸ì¡° ìƒì€ ê°ì²´ ì‚­ì œ)
                    torch.cuda.empty_cache()  # 2. PyTorchê°€ ì¡ê³  ìˆëŠ” ë¹ˆ ë©”ëª¨ë¦¬ ìºì‹œ í•´ì œ
                    torch.cuda.synchronize()
                # 5. Config ì¡°ë¦½ ë° ì‹¤í–‰
                cfg = compose(config_name="config", overrides=overrides)
                run_experiment(cfg)

            except Exception as e:
                print(f"âŒ Error in experiment layer 2 {i + 1}: {e}")
                traceback.print_exc()

            finally:
                # 6. ë©”ëª¨ë¦¬ ì²­ì†Œ
                gc.collect()
                torch.cuda.empty_cache()

        for i, combination in enumerate(combinations):
            # í˜„ì¬ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
            param_dict = dict(zip(keys, combination))

            # ì§„í–‰ìƒí™© ì¶œë ¥
            print(f"\n==========================================================")
            print(f"ğŸ§© [Grid Search layer 3 {i + 1}/{len(combinations)}] Params: {param_dict}")

            d_name = param_dict["dataset"]
            m_name = param_dict["model"]

            # 3. Overrides ë¦¬ìŠ¤íŠ¸ ìƒì„± (ê¸°ë³¸ íŒŒë¼ë¯¸í„°)
            overrides = []
            for k, v in param_dict.items():
                overrides.append(f"{k}={v}")
            overrides.append("gpu_id=0")

            # [WandB Grouping] í•œ ëˆˆì— ë³´ê¸° ì¢‹ê²Œ ê·¸ë£¹ ì´ë¦„ ì„¤ì •
            # overrides.append(f"logging.experiment_strategy_name=GridSearch_v1")

            # 4. ì¡°ê±´ë¶€ ë¡œì§ (Logic) - ì•ˆì „ì¥ì¹˜ í¬í•¨
            is_large_dataset = d_name in ["ogbn-products", "ogbn-arxiv"]

            # (1) ìƒ˜í”ŒëŸ¬ í™œì„±í™” ì—¬ë¶€ ë° ë°°ì¹˜ ì‚¬ì´ì¦ˆ ê²°ì •
            if is_large_dataset or m_name == "graphsage":
                overrides.append("dataset.use_sampler=true")
                overrides.append("sampler.batch_size=512")

                # ë°ì´í„°ì…‹ë³„ ë°°ì¹˜ ì‚¬ì´ì¦ˆ
                if is_large_dataset:
                    overrides.append("sampler.batch_size=1024")
            else:
                overrides.append("dataset.use_sampler=false")

            if d_name == "ogbn-products":
                overrides.append("train.epochs=100")
            elif d_name == "ogbn-arxiv":
                overrides.append("train.epochs=80")
            elif d_name == "pubmed":
                overrides.append("train.epochs=140")
            elif d_name == "actor":
                overrides.append("train.epochs=250")
            elif d_name == "citeseer":
                overrides.append("train.epochs=180")
            elif d_name == "cora":
                overrides.append("train.epochs=150")

            # (2) ëª¨ë¸ë³„ ë ˆì´ì–´ ë° ìƒ˜í”ŒëŸ¬ ì‚¬ì´ì¦ˆ ë§¤ì¹­ (ì¤‘ìš”!)
            overrides.append("model.num_layers=3")
            overrides.append("model.sizes=[15,10,5]")

            try:
                # 5. Config ì¡°ë¦½ ë° ì‹¤í–‰
                cfg = compose(config_name="config", overrides=overrides)
                run_experiment(cfg)

            except Exception as e:
                print(f"âŒ Error in experiment layer 3 - {i + 1}: {e}")
                traceback.print_exc()

            finally:
                # 6. ë©”ëª¨ë¦¬ ì²­ì†Œ
                gc.collect()
                torch.cuda.empty_cache()


if __name__ == "__main__":
    os.environ["CUDA_VISIBLE_DEVICES"] = "2"

    run_grid_search()
